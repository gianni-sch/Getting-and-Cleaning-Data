sapply(packages, require, character.only=TRUE, quietly=TRUE)
library(data.table)
packages <- c("data.table", "sqldf")
library(data.table)
sapply(packages, require, character.only=TRUE, quietly=TRUE)
library(sqldf)
acs <- data.table(read.csv(f))
library(RMySQL)
acs <- data.table(read.csv(f))
install.packages(data.table)
install.packages("data.table")
library(data.table)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
packages <- c("data.table", "sqldf")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
packages <- c("data.table", "sqldf")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf()
sqldf(acs)
packages <- c("data.table", "sqldf")
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
acs <- data.table(read.csv(f))
sqldf::sqldf(acs)
query2 <- sqldf("select pwgtp1 from acs")
sqldf("select pwgtp1 from acs")
library(sqldf)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
acs <- data.table(read.csv(f))
library(data.table)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query1
query2 <- sqldf("select pwgtp1 from acs")
query3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
query4 <- sqldf("select * from acs where AGEP < 50")
identical(query3, query4)
gold <- unique(acs$AGEP)
query1 <- sqldf("select distinct AGEP from acs")
query2 <- sqldf("select AGEP where unique from acs")
query3 <- sqldf("select unique * from acs")
query4 <- sqldf("select unique AGEP from acs")
identical(gold, query1)
identical(gold, query2)
identical(gold, query3)
identical(gold, query4)
query1 <- sqldf("select distinct AGEP from acs")
query2 <- sqldf("select AGEP where unique from acs")
query3 <- sqldf("select unique AGEP from acs")
query4 <- sqldf("select distinct pwgtp1 from acs")
identical(gold, query4)
gold <- unique(acs$AGEP)
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
require(httr)
require(XML)
htmlCode <- GET("http://biostat.jhsph.edu/~jleek/contact.html")
content <- content(htmlCode, as="text")
htmlParsed <- htmlParse(content, asText=TRUE)
xpathSApply(htmlParsed, "//title", xmlValue)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("Coursera", "cc40465b58430daccbeb", secret="a87a96e588e5881be0425e907fcd75b5f04ccbed
")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
req <- GET("http://api.github.com/users/jtleek/repos", config(token = github_token))
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
req <- GET("http://api.github.com/users/jtleek/repos", config(token = github_token))
req <- GET("http://api.github.com/users/jtleek/repos", config(token = github_token))
list(output[[4]]$name, output[[4]]$created_at)
list(output[[4]]$name, output[[4]]$created_at)
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("Coursera", "cc40465b58430daccbeb", secret="a87a96e588e5881be0425e907fcd75b5f04ccbed")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
output$name
output[[]]$name
output[]$name
output[:]$name
output
output[[1]]
output["repo"]
output[["repo"]]
output["repo"]
list(output[[4]]$name, output[[4]]$created_at)
list(output[[1]]$name, output[[4]]$created_at)
list(output[[2]]$name, output[[4]]$created_at)
list(output[[3]]$name, output[[4]]$created_at)
output["repo"]
output
output["datashare"]
names(output)
table(output)
head(houtput)
head(output)
head(output,10)
output[name="repo"]
output[["repo"]]
output[[repo]]
dim(output)
output[[1]]
output[[1]]$name
output[[2]]$name
output[[3]]$name
for i=1:30 {}
output[[1:30]]$name
output[[3]]$name
output[[4]]$name
output[[5]]$name
output[[6]]$name
output[[7]]$name
output[[7]]
setwd("~/workspace/Practical_Machine_Learning")
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
head(adData)
head(adData,1)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(IL, method='pca', thresh=0.9,outcome=training$diagnosis)
preProc$rotation
preProc <- preProcess(IL, method='pca', thresh=0.99,outcome=training$diagnosis)
preProc$rotation
preProc <- preProcess(IL, method='pca', thresh=0.8,outcome=training$diagnosis)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
dataframe <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(dataframe$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
training <- dataframe[inTrain, ]
testing <- dataframe[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
NONPCA <- C1$overall[1]
NONPCA
modelFit <- train(training$diagnosis ~ ., method="glm", preProcess="pca", data=training,trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
PCA <- C2$overall[1]
PCA
setwd("/home/gianfranco/workspace/Practical_Machine_Learning")
load("project-calc.R"
)
load("project-calc.R")
load("project-calc.R")
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/home/gianfranco/workspace/Practical_Machine_Learning")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
testing_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training)
cleantraining <- training_data[, -which(names(training_data) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(testing_data)-1)) {testing_data[,i] = as.numeric(as.character(testing_data[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(modeldata$classe, p=0.6, list=FALSE )
training <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
m
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, training[, -length(names(training))])
result
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel)
##############################
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
testing_data <- testing_data[featureset[featureset!='classe']]
answers <- predict(model, newdata=testing_data)
answers
pml_write_files(answers)
setwd("/home/gianfranco/workspace/Practical_Machine_Learning")
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
setwd("/home/gianfranco/workspace/Practical_Machine_Learning")
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
load("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
setwd("/home/gianfranco/workspace/Practical_Machine_Learning")
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
load <- function(package){
new.package <- package[!(package %in% installed.packages()[, "Package"])]
if (length(new.package))
install.packages(new.package, dependencies = TRUE)
sapply(package, require, character.only = TRUE)
}
trainFile <- "pml-training.csv"
testFile  <- "pml-testing.csv"
if (!file.exists(trainFile)) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile=trainFile, method="curl")
}
if (!file.exists(trainFile)) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile=testFile, method="curl",quiet=TRUE)
}
training <- read.csv(trainFile)
testing <- read.csv(testFile)
dim(training)
dim(testing)
summary(training$classe)
sum(complete.cases(training))
trainingCleaned <- training[, colSums(is.na(training)) == 0]
dim(trainingCleaned)
nzv <- nearZeroVar(trainingCleaned, saveMetrics=TRUE)
load(caret)
libary(caret)
library(caret)
nzv <- nearZeroVar(trainingCleaned, saveMetrics=TRUE)
trainingCleaned <- trainingCleaned[, nzv[,"nzv"] == FALSE]
dim(trainingCleaned)
trainingCleaned <- trainingCleaned[, -grep("timestamp|user_name|new_window|num_window|X", names(trainingCleaned))]
dim(trainingCleaned)
set.seed(1234)
inTrain <- createDataPartition(trainingCleaned$classe, p=0.7, list=FALSE)
trainingData <- trainingCleaned[inTrain,]
validationData <- trainingCleaned[-inTrain, ]
modelRF <- train(classe ~ .,
data=trainingData, method="rf",
trControl=trainControl(method="cv", number=5),
prox=TRUE,
allowParallel=TRUE,
ntree=250)
modelRF
model <- train(classe ~ .,
data=trainingData, method="rf",
trControl=trainControl(method="cv", number=5),
prox=TRUE,
allowParallel=TRUE,
ntree=250)
library(caret)
model <- train(classe ~ .,
data=trainingData, method="rf",
trControl=trainControl(method="cv", number=5),
prox=TRUE,
allowParallel=TRUE,
ntree=250)
numCores <- detectCores()
registerDoMC(cores = numCores - 1)
install.package("doMC")
install.packages("doMC")
install.packages(doMC)
install.packages("doMC")
install.packages("doMC")
install.packages("doMC")
install.packages("doMC")
install.packages("doMC")
library(doMC)
numCores <- detectCores()
registerDoMC(cores = numCores - 1)
library(caret)
time()
time(x)
time()
timestamp(stamp = date(),
prefix = "##------ ", suffix = " ------##",
quiet = FALSE)
##------ Sun Sep 27 01:20:15 2015 ------##
model <- train(classe ~ .,
data=trainingData, method="rf",
trControl=trainControl(method="cv", number=5),
prox=TRUE,
allowParallel=TRUE,
ntree=250)
timestamp(stamp = date(),
prefix = "##------ ", suffix = " ------##",
quiet = FALSE)
##------ Sun Sep 27 03:34:38 2015 ------##
model
predict <- predict(model, validation)
predict <- predict(model, validationData)
confusionMatrix(validationData$classe, predict)
accuracy <- postResample(predict, validation$classe)
accuracy <- postResample(predict, validationData$classe)
accuracy
oose <- sum(predict != validationData$classe) * 100 / nrow(validationData)
round(confusionMatrix(validationData$classe, predictRF)$overall[1]*100, 2)
round(confusionMatrix(validationData$classe, predict)$overall[1]*100, 2)
round(oose, 2)
testData <- testing[, names(testing) %in% names(trainingCleaned)]
result <- predict(model, newdata=testData)
result
modelTree <- rpart(classe ~ ., data=trainingCleaned, method="class")
library(rpart)
modelTree <- rpart(classe ~ ., data=trainingCleaned, method="class")
prp(modelTree)
library(rpart.plot)
prp(modelTree)
head(training,1)
result
top <- varImp(model)
plot(top, main = "Top 10 most influencial predictors", top = 10)
plot(model, main="Model accuracy by predictors")
plot(model, main="Model Accuracy Vs Predictors")
plot(model$finalModel, main="Error rate Vs Number of Trees")
featureset <- colnames(trainingCleaned[colSums(is.na(trainingCleaned)) == 0])[-(1:7)]
featureset <- colnames(trainingCleaned)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
testing_data <- testing_data[featureset[featureset!='classe']]
testing_data <- testing[featureset[featureset!='classe']]
answers <- predict(model, newdata=testing_data)
answers
pml_write_files(answers)
featureset <- colnames(trainingCleaned)
date()
featureset <- colnames(trainingCleaned)
ingCleaned)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
testing_data <- testing[featureset[featureset!='classe']]
answers <- predict(model, newdata=testing_data)
answers
pml_write_files(answers)
numCores <- detectCores()
registerDoMC(cores = numCores - 1)
title: "Pratical Machine Learning Project; Human Activity Recognition with Random Forest Algorithm"
numCores
setwd("/home/gianfranco/workspace/GetAndCleaningData")
setwd("/home/gianfranco/workspace/GetAndCleaningData/Project")
packages <- c("data.table", "reshape2")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
path <- getwd()
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(path)) {dir.create(path)}
download.file(url, file.path(path, f))
unzip(file.path(path, f), files = NULL, list = FALSE, overwrite = TRUE,
junkpaths = FALSE, exdir = ".", unzip = "internal",
setTimes = FALSE)
pathInput <- file.path(path, "UCI HAR Dataset")
list.files(pathInput, recursive=TRUE)
subjectTrain <- fread(file.path(pathIn, "train", "subject_train.txt"))
subjectTrain <- fread(file.path(pathInput, "train", "subject_train.txt"))
subjectTest  <- fread(file.path(pathInput, "test" , "subject_test.txt" ))
activityTrain <- fread(file.path(pathInput, "train", "Y_train.txt"))
activityTrain <- fread(file.path(pathInput, "train", "y_train.txt"))
activityTest  <- fread(file.path(pathInput, "test" , "y_test.txt" ))
fileToDataTable <- function (f) {
df <- read.table(f)
dt <- data.table(df)
}
dataTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
dataTrain <- fileToDataTable(file.path(pathInput, "train", "X_train.txt"))
dataTest  <- fileToDataTable(file.path(pathInput, "test" , "X_test.txt" ))
subject <- rbind(subjectTrain, subjectTest)
setnames(subject, "V1", "subject")
activity <- rbind(activityTrain, activityTest)
setnames(activity, "V1", "activityNum")
data <- rbind(dataTrain, dataTest)
subject <- cbind(subject, activity)
data <- cbind(subject, data)
setkey(data, subject, activityNum)
features <- fread(file.path(pathInput, "features.txt"))
setnames(features, names(features), c("featureNum", "featureName"))
features <- features[grepl("mean\\(\\)|std\\(\\)", featureName)]
features$featureCode <- features[, paste0("V", featureNum)]
head(features)
features$featureCode
selectFeature <- c(key(data), features$featureCode)
data <- data[, selectFeature, with=FALSE]
activityNames <- fread(file.path(pathInput, "activity_labels.txt"))
setnames(activityNames, names(activityNames), c("activityNum", "activityName"))
data <- merge(data, activityNames, by="activityNum", all.x=TRUE)
setkey(data, subject, activityNum, activityName)
data <- data.table(melt(data, key(data), variable.name="featureCode"))
data$activity <- factor(data$activityName)
data$feature <- factor(data$featureName)
data$feature <- factor(data$featureName)
data$feature <- factor(data$featureName)
data$featureName
data$activityName
